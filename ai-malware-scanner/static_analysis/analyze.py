import os
import logging
import numpy as np
import lief
import hashlib
import magic
import re
from collections import Counter
# Change from relative import to absolute import
from static_analysis.entropy import shannon_entropy

# Initialize logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def get_imphash(binary):
    """Calculate import hash for PE file using LIEF."""
    try:
        imports = []
        for imported_library in binary.imports:
            library_name = imported_library.name.lower()
            for function in imported_library.entries:
                if function.name:
                    imports.append(f"{library_name}.{function.name}")
        imports = sorted(imports)
        import_str = ",".join(imports)
        return hashlib.md5(import_str.encode()).hexdigest()
    except Exception as e:
        logger.error(f"Error calculating imphash: {e}")
        return None

def extract_static_features(file_path):
    """Extract comprehensive static features from binary files using LIEF."""
    try:
        # Check if file exists and is accessible
        if not os.path.exists(file_path):
            logger.error(f"File does not exist: {file_path}")
            return None
            
        if not os.access(file_path, os.R_OK):
            logger.error(f"No permission to read file: {file_path}")
            return None
            
        # Basic file info
        file_size = os.path.getsize(file_path)
        
        # Handle very large files
        if file_size > 100 * 1024 * 1024:
            logger.warning(f"File is very large ({file_size/1024/1024:.2f} MB), may cause memory issues: {file_path}")
        
        # Use more robust file type detection
        try:
            file_magic = magic.from_file(file_path)
            file_type = magic.from_file(file_path, mime=True)
        except Exception as e:
            logger.error(f"Error determining file type: {e}")
            file_magic = "unknown"
            file_type = "application/octet-stream"
        
        # Calculate hashes
        try:
            with open(file_path, "rb") as f:
                file_data = f.read()
                md5_hash = hashlib.md5(file_data).hexdigest()
                sha1_hash = hashlib.sha1(file_data).hexdigest()
                sha256_hash = hashlib.sha256(file_data).hexdigest()
        except Exception as e:
            logger.error(f"Error reading file or calculating hashes: {e}")
            return None
        
        # Check if file is a PE file
        is_pe = False
        features = {
            "file_size": file_size,
            "file_type": file_type,
            "file_magic": file_magic,
            "md5": md5_hash,
            "sha1": sha1_hash,
            "sha256": sha256_hash,
            "entropy": shannon_entropy(file_data)
        }
        
        # PE specific features
        if "PE32" in file_magic or "PE32+" in file_magic:
            is_pe = True
            try:
                binary = lief.parse(file_path)
                if binary:
                    # Header info
                    features.update({
                        "is_pe": True,
                        "imphash": get_imphash(binary),
                        "entry_point": binary.optional_header.addressof_entrypoint,
                        "image_base": binary.optional_header.imagebase,
                        "num_sections": len(binary.sections),
                        "num_directories": len(binary.data_directories),
                        "compile_time": binary.header.time_date_stamps,
                        "virtual_size": binary.optional_header.sizeof_image,
                        "has_debug": binary.has_debug,
                        "has_tls": binary.has_tls,
                        "has_resources": binary.has_resources,
                        "has_relocations": binary.has_relocations,
                        "has_signature": binary.has_signatures,
                        "has_nx": getattr(binary.optional_header, "has_nx", False),
                        "has_no_seh": getattr(binary.optional_header, "has_no_seh", False),
                    })
                    
                    # Import features
                    imports = Counter()
                    if binary.has_imports:
                        for imported_library in binary.imports:
                            for function in imported_library.entries:
                                if function.name:
                                    imports[function.name] += 1
                    features["num_imports"] = sum(imports.values())
                    
                    # Section features
                    section_names = [section.name for section in binary.sections]
                    section_entropies = [shannon_entropy(section.content) for section in binary.sections]
                    section_sizes = [section.size for section in binary.sections]
                    features["sections"] = section_names
                    features["section_entropies"] = section_entropies
                    features["section_sizes"] = section_sizes
                    features["avg_section_entropy"] = np.mean(section_entropies) if section_entropies else 0
                else:
                    logger.error(f"LIEF couldn't parse the PE file: {file_path}")
                    features["is_pe"] = False
            except Exception as e:
                logger.error(f"Error analyzing PE file with LIEF: {str(e)}")
                features["is_pe"] = False
                features["lief_error"] = str(e)
        else:
            features["is_pe"] = False
        
        # Extract strings for all file types
        try:
            strings_pattern = re.compile(b'[\x20-\x7f]{5,}')
            strings = strings_pattern.findall(file_data)
            features["strings"] = [s.decode(errors='ignore') for s in strings[:1000]]  # Limit to first 1000 strings
            features["num_strings"] = len(strings)
        except Exception as e:
            logger.error(f"Error extracting strings: {e}")
            features["strings"] = []
            features["num_strings"] = 0
        
        return features
    except Exception as e:
        logger.error(f"Unhandled error processing file {file_path}: {e}")
        return None

def vectorize_features(features):
    """Convert extracted features to numerical vector for model input.
    IMPORTANT: This vector must match the Ember dataset feature order.
    """
    if not features:
        logger.error("No features provided to vectorize")
        return None

    if not features.get("is_pe", False):
        logger.info("Not vectorizing non-PE file")
        return None

    try:
        # Build Ember feature vector.
        # Note: Map extracted features to Ember columns.
        # For missing features, we use default value 0.
        feature_vector = [
            features.get("file_size", 0),                # maps to 'size'
            features.get("entropy", 0),                    # 'entropy'
            features.get("num_strings", 0),                # 'numstrings'
            0,                                           # 'byteentropy' (not extracted)
            0,                                           # 'histogram' (not extracted)
            0,                                           # 'avlength' (not extracted)
            0,                                           # 'printabledist' (not extracted)
            0,                                           # 'printables' (not extracted)
            features.get("entry_point", 0),              # 'entry'
            features.get("virtual_size", 0),             # 'vsize'
            int(features.get("has_debug", False)),       # 'has_debug'
            int(features.get("has_tls", False)),         # 'has_tls'
            int(features.get("has_resources", False)),   # 'has_resources'
            int(features.get("has_relocations", False)), # 'has_relocations'
            int(features.get("has_signature", False)),   # 'has_signature'
            features.get("num_imports", 0),              # 'imports_counts'
            # For the remaining Ember columns that are not yet extracted,
            # use default values. Adjust the number of zeros below to match
            # the required Ember input length.
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0
        ]
        return feature_vector
    except Exception as e:
        logger.error(f"Error vectorizing features: {e}")
        return None
